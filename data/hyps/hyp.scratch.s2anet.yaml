
# 在本代码中，调整batch-size时，学习率可以不用调整
lr0: 0.005  # initial learning rate (SGD=1E-2, Adam=1E-3)
lrf: 0.005  # final OneCycleLR learning rate (lr0 * lrf)
momentum: 0.9  # SGD momentum/Adam beta1
weight_decay: 0.0001  # optimizer weight decay 5e-4
# warmup_epochs: 3.0  # warmup epochs (fractions ok)
warmup_iters: 500  # 最大的warmup的迭代次数，与warmup_epochs确定的迭代次数相比较，最终warmup的迭代次数取两者间最大的

warmup_momentum: 0.8  # warmup initial momentum
warmup_bias_lr: 0.0  # warmup initial bias lr


hsv_h: 0.0  # image HSV-Hue augmentation (fraction)
hsv_s: 0.0  # image HSV-Saturation augmentation (fraction)
hsv_v: 0.0  # image HSV-Value augmentation (fraction)
degrees: 180.0  # random angle in [-180, -90, 0, 90]
translate: 0.0  # image translation (+/- fraction)
scale: 0.0  # image scale (+/- gain)
shear: 0.0  # image shear (+/- deg)
perspective: 0.0  # image perspective (+/- fraction), range 0-0.001
flipud: 0.0  # image flip up-down (probability)
fliplr: 0.5  # image flip left-right (probability)
mosaic: 0.0  # image mosaic (probability)
mixup: 0.0  # image mixup (probability)
copy_paste: 0.0  # segment copy-paste (probability)